# Multimodal RAG: Chat with Videos ğŸ¥ğŸ’¬

## Overview ğŸŒŸ
This project implements a Multimodal Retrieval-Augmented Generation (RAG) system that enables chatting with videos. It processes video content using advanced techniques for frame extraction, transcription, and contextual responses.
![Screenshot 2024-10-02 192836](https://github.com/user-attachments/assets/82e0176c-eefd-4191-a28b-18a842e375be)

## Features ğŸš€
- **Video Preprocessing**:
  - Frame extraction and transcription using **Whisper**.
  - Image captioning and visual Q&A with **Large Vision Language Models (LVLMs)** like **LLaVA**.

- **Multimodal Vector Databases**:
  - Implementing retrieval with **LanceDB** and **LangChain** for efficient vector storage.

## Workflow ğŸ”„
1. Process videos (frames, transcripts, captions).
2. Store data in a vector database.
3. Retrieve relevant video segments and generate contextual responses.

## Technologies Used ğŸ› ï¸
- **BridgeTower**: Image-caption embedding.
- **Whisper**: Transcription service.
- **LLaVA**: Advanced LVLM for video content understanding.
- **LanceDB & LangChain**: Vector storage and retrieval solutions.

## About Me ğŸ‘¤
**Mustafa Shoukat**  
- **Role**: Data Scientist and AI/ML Engineer  
- **Location**: Lahore, Pakistan  
- **Specializations**: Machine Learning, Deep Learning, NLP, Generative AI, RAG, and Building AI Agents.  
- **GitHub**: [Mustafa Shoukat](https://github.com/YourGitHubUsername)  
- **LinkedIn**: [Mustafa Shoukat](https://www.linkedin.com/in/YourLinkedInProfile)  

